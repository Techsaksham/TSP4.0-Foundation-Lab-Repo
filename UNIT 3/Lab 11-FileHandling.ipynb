{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xilNRt__UfKV"
   },
   "source": [
    "# Set up \n",
    "\n",
    "- this notebook needs the `Machine_Learning_AI.txt` file to work with\n",
    "\n",
    "### If you're running Google Collab \n",
    "- if you're running google collabs,  \n",
    "  - load the file into your google drive, locate the file in google drive via google collab, then copy the path and paste the path in the variable called `file_path` in the cell below \n",
    "\n",
    "### If you're running a Local Jupyter Notebook \n",
    "- if you're running a Jupyter Notebooks locally from Anaconda Navigator or VS Code, downlaod the file and save it locally in the same folder as the notebook \n",
    "  - then get the path for the file and paste it in code cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HInwYs98Vhi5"
   },
   "outputs": [],
   "source": [
    "file_path = \"Machine_Learning_AI.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4BKjpLMULuh"
   },
   "source": [
    "# Reading Files\n",
    "\n",
    "- use the built-in `open` function\n",
    "  - a file object has to be created first\n",
    "  - then obtain data from file\n",
    "\n",
    "- we are using a text file in our example here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "muElQbSFgGfI"
   },
   "source": [
    "### `open` and `close` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfBAMyINTmST"
   },
   "outputs": [],
   "source": [
    "# code to open file:\n",
    "our_text_file = open(file_path,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "247dX677fLRm"
   },
   "source": [
    "- here:\n",
    "  - `our_text_file`: new file object\n",
    "  - `open`: keyword to open a file\n",
    "  - `file_path`: variable containing the file path string \n",
    "    - this can be the actual file path string as well\n",
    "  - `'r'`: the mode of opening the file\n",
    "    - popular modes of file reading:\n",
    "      - `'r'`: reading mode\n",
    "      - `'w'`: writing mode\n",
    "      - `'a'`: appending mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ps-wjvIhfK6V",
    "outputId": "62614525-a82d-4656-b4e5-4cc2a41fcf92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine_Learning_AI.txt\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "# gather info about the file we opened i nthe previous code cell\n",
    "print(our_text_file.name)\n",
    "print(our_text_file.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqnYxTkkf1p-"
   },
   "outputs": [],
   "source": [
    "# close the open file \n",
    "our_text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOnDbcVgf2_s"
   },
   "source": [
    "### `with` keyword \n",
    "\n",
    "- everytime a file is opened, it has to be closed; else it occupies mememory unnecessarily and in some cases turns into a security flaw\n",
    "  - opening and closing the file gets tedious \n",
    "- so the `with` keyword is used as it automatically opens and closes the file \n",
    "  - using the `with` keyword is the best practise for working with files \n",
    "  - the `with` keyword opens the file in the file path, runs everything in the indent code block and closes the file automatically\n",
    "  - the file content will not be available outside the code block, however, but the file content can be saved into variables for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s7dkbFm2glXd",
    "outputId": "d624a897-0a78-4cdb-8d69-f4f3bc61358f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit 1: Introduction To Python - \n",
      "\n",
      "Intro to the Python Programming language\n",
      "Control structures and functions\n",
      "Importing libraries - Numpy and Pandas Basics\n",
      "Data wrangling and cleaning\n",
      "Exploratory Data Analysis and descriptive statistics\n",
      "\n",
      "Unit 2: Database Management - \n",
      "\n",
      "Introduction to Databases and SQL\n",
      "Retrieving data with SQL\n",
      "Writing SQL Queries\n",
      "Functions and aggregations\n",
      "Joins in SQL\n",
      "\n",
      "Unit 3: Statistics and Data Visualisation - \n",
      "\n",
      "Data Visualisation using matplotlib/seaborn\n",
      "Plotting Data distributions\n",
      "Introduction to probability\n",
      "Discrete and Continuous probability distributions\n",
      "Inferential Statistics and Hypothesis testing\n",
      "\n",
      "Unit 4: Machine Learning:\n",
      "\n",
      "Introduction to machine learning models \n",
      "Simple and Multiple Regression Models\n",
      "Logistic Regression\n",
      "ROC and AUC analysis\n",
      "KNN and Naive Bayes classifier\n",
      "SVM Classification and Regression\n",
      "Tree Based models:\n",
      "- Decision trees\n",
      "- Truncation and pruning\n",
      "- Random Forests and Bagged models\n",
      "- Gradient Boosted models\n",
      "Feature selection methods \n",
      "Model evaluation and hyper parameter tuning \n",
      "Unsupervised Learning:\n",
      "- Clustering (K means and Hierarchical)\n",
      "- Principal Component Analysis\n",
      "Recommender Systems\n",
      "\n",
      "Unit 5 - Artificial Intelligence:\n",
      "\n",
      "Intro to Neural Networks\n",
      "Types of Neural Networks\n",
      "Image classification\n",
      "Deep Learning Neural Networks\n",
      "\n",
      "Intro to NLP\n",
      "Basic Lexical processing\n",
      "Text classification / Topic modelling / Document summarisation\n",
      "Reinforcement Learning Models\n",
      "\n",
      "Notes:\n",
      "\n",
      "Unit 5 could probability be split in 2 depending on how comprehensive the coverage is\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code pattern for opening a file using `with` keyword\n",
    "with open(file_path,\"r\") as active_file:\n",
    "  file_content = active_file.read()\n",
    "  print(file_content)\n",
    "\n",
    "# here: `active_file` is the file object \n",
    "# `open` is the file opening keyword \n",
    "# '.read()` reads the content of the text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uc1Fdo6TheCU"
   },
   "source": [
    "- so `with` was used to read the file content from the file `\"/content/drive/My Drive/Colab Notebooks/Machine_Learning_AI.txt\"` which is saved google drive in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OQom2SVFhsZl",
    "outputId": "8ae8d333-502c-4e6f-a7e6-a93f90bd8124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if file is closed \n",
    "print(active_file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RZa-q5CLhxSF",
    "outputId": "c70318af-d541-4b98-8e22-28aa674f8584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit 1: Introduction To Python - \n",
      "\n",
      "Intro to the Python Programming language\n",
      "Control structures and functions\n",
      "Importing libraries - Numpy and Pandas Basics\n",
      "Data wrangling and cleaning\n",
      "Exploratory Data Analysis and descriptive statistics\n",
      "\n",
      "Unit 2: Database Management - \n",
      "\n",
      "Introduction to Databases and SQL\n",
      "Retrieving data with SQL\n",
      "Writing SQL Queries\n",
      "Functions and aggregations\n",
      "Joins in SQL\n",
      "\n",
      "Unit 3: Statistics and Data Visualisation - \n",
      "\n",
      "Data Visualisation using matplotlib/seaborn\n",
      "Plotting Data distributions\n",
      "Introduction to probability\n",
      "Discrete and Continuous probability distributions\n",
      "Inferential Statistics and Hypothesis testing\n",
      "\n",
      "Unit 4: Machine Learning:\n",
      "\n",
      "Introduction to machine learning models \n",
      "Simple and Multiple Regression Models\n",
      "Logistic Regression\n",
      "ROC and AUC analysis\n",
      "KNN and Naive Bayes classifier\n",
      "SVM Classification and Regression\n",
      "Tree Based models:\n",
      "- Decision trees\n",
      "- Truncation and pruning\n",
      "- Random Forests and Bagged models\n",
      "- Gradient Boosted models\n",
      "Feature selection methods \n",
      "Model evaluation and hyper parameter tuning \n",
      "Unsupervised Learning:\n",
      "- Clustering (K means and Hierarchical)\n",
      "- Principal Component Analysis\n",
      "Recommender Systems\n",
      "\n",
      "Unit 5 - Artificial Intelligence:\n",
      "\n",
      "Intro to Neural Networks\n",
      "Types of Neural Networks\n",
      "Image classification\n",
      "Deep Learning Neural Networks\n",
      "\n",
      "Intro to NLP\n",
      "Basic Lexical processing\n",
      "Text classification / Topic modelling / Document summarisation\n",
      "Reinforcement Learning Models\n",
      "\n",
      "Notes:\n",
      "\n",
      "Unit 5 could probability be split in 2 depending on how comprehensive the coverage is\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if content is saved for later use\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kmW51BBvlzNc",
    "outputId": "4c75ff9d-e449-44bd-945d-4871a41a79a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517\n"
     ]
    }
   ],
   "source": [
    "# check the length of the file content (number of characters of the file)\n",
    "print(len(file_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3x0i1Lvh8Y3"
   },
   "source": [
    "### reading file content: `.readlines()`\n",
    "\n",
    "- the above output is just a huge block of text \n",
    "- it needs to be more manageable \n",
    "  - so the file content is read and converted to a list while using the `with` operation\n",
    "- the `readlines()` method reads lines one by one \n",
    "  - this can be stored into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "T67MAnOGiTWs",
    "outputId": "b7812dcc-55af-4879-8b1e-38a78d0205ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit 1: Introduction To Python - \n",
      "\n",
      "Introduction to Databases and SQL\n",
      "\n",
      "Reinforcement Learning Models\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open file using `with` keyword\n",
    "with open(file_path,\"r\") as active_file:\n",
    "  \n",
    "  # convert file content to a list\n",
    "  file_content_list = active_file.readlines()\n",
    "\n",
    "  # output single elements from the list \n",
    "  # (they correspond to lines of the text file)\n",
    "  print(file_content_list[0]) # prints the 1st line\n",
    "  print(file_content_list[10]) # prints the 11th line\n",
    "  print(file_content_list[54]) # prints the 55th line \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CblGiY1Np66E"
   },
   "source": [
    "- next, we check all the lines read by the `with` code block \n",
    "  - also get the number of lines in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BS3fMiGXjug8",
    "outputId": "4e5baada-528f-4ff3-b6b4-3534bc39f55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unit 1: Introduction To Python - \\n', '\\n', 'Intro to the Python Programming language\\n', 'Control structures and functions\\n', 'Importing libraries - Numpy and Pandas Basics\\n', 'Data wrangling and cleaning\\n', 'Exploratory Data Analysis and descriptive statistics\\n', '\\n', 'Unit 2: Database Management - \\n', '\\n', 'Introduction to Databases and SQL\\n', 'Retrieving data with SQL\\n', 'Writing SQL Queries\\n', 'Functions and aggregations\\n', 'Joins in SQL\\n', '\\n', 'Unit 3: Statistics and Data Visualisation - \\n', '\\n', 'Data Visualisation using matplotlib/seaborn\\n', 'Plotting Data distributions\\n', 'Introduction to probability\\n', 'Discrete and Continuous probability distributions\\n', 'Inferential Statistics and Hypothesis testing\\n', '\\n', 'Unit 4: Machine Learning:\\n', '\\n', 'Introduction to machine learning models \\n', 'Simple and Multiple Regression Models\\n', 'Logistic Regression\\n', 'ROC and AUC analysis\\n', 'KNN and Naive Bayes classifier\\n', 'SVM Classification and Regression\\n', 'Tree Based models:\\n', '- Decision trees\\n', '- Truncation and pruning\\n', '- Random Forests and Bagged models\\n', '- Gradient Boosted models\\n', 'Feature selection methods \\n', 'Model evaluation and hyper parameter tuning \\n', 'Unsupervised Learning:\\n', '- Clustering (K means and Hierarchical)\\n', '- Principal Component Analysis\\n', 'Recommender Systems\\n', '\\n', 'Unit 5 - Artificial Intelligence:\\n', '\\n', 'Intro to Neural Networks\\n', 'Types of Neural Networks\\n', 'Image classification\\n', 'Deep Learning Neural Networks\\n', '\\n', 'Intro to NLP\\n', 'Basic Lexical processing\\n', 'Text classification / Topic modelling / Document summarisation\\n', 'Reinforcement Learning Models\\n', '\\n', 'Notes:\\n', '\\n', 'Unit 5 could probability be split in 2 depending on how comprehensive the coverage is\\n', '\\n']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# open file using `with` keyword\n",
    "with open(file_path,\"r\") as active_file:\n",
    "  \n",
    "  # convert file content to a list using `.readlines()`\n",
    "  file_content_list = active_file.readlines()\n",
    "\n",
    "  # print all file lines as a list \n",
    "  print(file_content_list)\n",
    "\n",
    "  # get the number of lines in the file \n",
    "  print(len(file_content_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHDwnfSdlJ5O"
   },
   "source": [
    "- after saving the file lines to a list, it can be looped over with a `for` loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uvO1F2kzlJUq",
    "outputId": "883e7891-e29c-4b6b-920e-39dac1b46d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "1\n",
      "41\n",
      "33\n",
      "46\n",
      "28\n",
      "53\n",
      "1\n",
      "31\n",
      "1\n",
      "34\n",
      "25\n",
      "20\n",
      "27\n",
      "13\n",
      "1\n",
      "45\n",
      "1\n",
      "44\n",
      "28\n",
      "28\n",
      "50\n",
      "46\n",
      "1\n",
      "26\n",
      "1\n",
      "41\n",
      "38\n",
      "20\n",
      "21\n",
      "31\n",
      "34\n",
      "19\n",
      "17\n",
      "25\n",
      "35\n",
      "26\n",
      "27\n",
      "45\n",
      "23\n",
      "40\n",
      "31\n",
      "20\n",
      "1\n",
      "34\n",
      "1\n",
      "25\n",
      "25\n",
      "21\n",
      "30\n",
      "1\n",
      "13\n",
      "25\n",
      "63\n",
      "30\n",
      "1\n",
      "7\n",
      "1\n",
      "86\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# setup for loop to scroll through all the lines in the file content list\n",
    "for line in file_content_list:\n",
    "  print(len(line)) # print the length of each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8N5I7X5mZSr"
   },
   "source": [
    "# Writing Files\n",
    "\n",
    "- use `with` `open` again to automatically open and close files\n",
    "  - `\"w\"`: mode to write to file \n",
    "  - `\"a\"`: mode to append to file\n",
    "  - `\"x\"`: mode to create a new file and open it for writing\n",
    "\n",
    "- use the `.write()` to write lines to the file inside the `with` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "ADXAEIAdmz0_",
    "outputId": "fd96800c-f0b9-4e35-bc1f-44319bc37fee"
   },
   "outputs": [],
   "source": [
    "# code pattern to create a new file and write to it \n",
    "with open('new_file.txt','x') as file_to_write:\n",
    "  file_to_write.write('this is line 0\\n')\n",
    "  file_to_write.write('this is line 1\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWN-IFT8nmEz"
   },
   "source": [
    "- check the newly created file in your file browser\n",
    "- if code throws a `\"FileExistsError: ... File exists: 'new_file.txt'\"` error , this means a file already exists with the same name\n",
    "  - so change the mode to `'w'` to write to the exisitng file, or change the file name to create a new file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4UDHWUXqMTO"
   },
   "source": [
    "- `for` loops can be used to write some list's content to a file within the `with` block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3f2pN2ogV0lm"
   },
   "source": [
    "# Additional Learning \n",
    "\n",
    "- research more about file object methods \n",
    "  - see help for syntax\n",
    "  - i.e. help(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dXhCoPsTV77e",
    "outputId": "fec8295f-7957-4770-fdbc-2b313b8ffe49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function open in module io:\n",
      "\n",
      "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
      "    Open file and return a stream.  Raise IOError upon failure.\n",
      "    \n",
      "    file is either a text or byte string giving the name (and the path\n",
      "    if the file isn't in the current working directory) of the file to\n",
      "    be opened or an integer file descriptor of the file to be\n",
      "    wrapped. (If a file descriptor is given, it is closed when the\n",
      "    returned I/O object is closed, unless closefd is set to False.)\n",
      "    \n",
      "    mode is an optional string that specifies the mode in which the file\n",
      "    is opened. It defaults to 'r' which means open for reading in text\n",
      "    mode.  Other common values are 'w' for writing (truncating the file if\n",
      "    it already exists), 'x' for creating and writing to a new file, and\n",
      "    'a' for appending (which on some Unix systems, means that all writes\n",
      "    append to the end of the file regardless of the current seek position).\n",
      "    In text mode, if encoding is not specified the encoding used is platform\n",
      "    dependent: locale.getpreferredencoding(False) is called to get the\n",
      "    current locale encoding. (For reading and writing raw bytes use binary\n",
      "    mode and leave encoding unspecified.) The available modes are:\n",
      "    \n",
      "    ========= ===============================================================\n",
      "    Character Meaning\n",
      "    --------- ---------------------------------------------------------------\n",
      "    'r'       open for reading (default)\n",
      "    'w'       open for writing, truncating the file first\n",
      "    'x'       create a new file and open it for writing\n",
      "    'a'       open for writing, appending to the end of the file if it exists\n",
      "    'b'       binary mode\n",
      "    't'       text mode (default)\n",
      "    '+'       open a disk file for updating (reading and writing)\n",
      "    'U'       universal newline mode (deprecated)\n",
      "    ========= ===============================================================\n",
      "    \n",
      "    The default mode is 'rt' (open for reading text). For binary random\n",
      "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
      "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
      "    raises an `FileExistsError` if the file already exists.\n",
      "    \n",
      "    Python distinguishes between files opened in binary and text modes,\n",
      "    even when the underlying operating system doesn't. Files opened in\n",
      "    binary mode (appending 'b' to the mode argument) return contents as\n",
      "    bytes objects without any decoding. In text mode (the default, or when\n",
      "    't' is appended to the mode argument), the contents of the file are\n",
      "    returned as strings, the bytes having been first decoded using a\n",
      "    platform-dependent encoding or using the specified encoding if given.\n",
      "    \n",
      "    'U' mode is deprecated and will raise an exception in future versions\n",
      "    of Python.  It has no effect in Python 3.  Use newline to control\n",
      "    universal newlines mode.\n",
      "    \n",
      "    buffering is an optional integer used to set the buffering policy.\n",
      "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
      "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
      "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
      "    given, the default buffering policy works as follows:\n",
      "    \n",
      "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
      "      is chosen using a heuristic trying to determine the underlying device's\n",
      "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
      "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
      "    \n",
      "    * \"Interactive\" text files (files for which isatty() returns True)\n",
      "      use line buffering.  Other text files use the policy described above\n",
      "      for binary files.\n",
      "    \n",
      "    encoding is the name of the encoding used to decode or encode the\n",
      "    file. This should only be used in text mode. The default encoding is\n",
      "    platform dependent, but any encoding supported by Python can be\n",
      "    passed.  See the codecs module for the list of supported encodings.\n",
      "    \n",
      "    errors is an optional string that specifies how encoding errors are to\n",
      "    be handled---this argument should not be used in binary mode. Pass\n",
      "    'strict' to raise a ValueError exception if there is an encoding error\n",
      "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
      "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
      "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
      "    for a list of the permitted encoding error strings.\n",
      "    \n",
      "    newline controls how universal newlines works (it only applies to text\n",
      "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
      "    follows:\n",
      "    \n",
      "    * On input, if newline is None, universal newlines mode is\n",
      "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      "      these are translated into '\\n' before being returned to the\n",
      "      caller. If it is '', universal newline mode is enabled, but line\n",
      "      endings are returned to the caller untranslated. If it has any of\n",
      "      the other legal values, input lines are only terminated by the given\n",
      "      string, and the line ending is returned to the caller untranslated.\n",
      "    \n",
      "    * On output, if newline is None, any '\\n' characters written are\n",
      "      translated to the system default line separator, os.linesep. If\n",
      "      newline is '' or '\\n', no translation takes place. If newline is any\n",
      "      of the other legal values, any '\\n' characters written are translated\n",
      "      to the given string.\n",
      "    \n",
      "    If closefd is False, the underlying file descriptor will be kept open\n",
      "    when the file is closed. This does not work when a file name is given\n",
      "    and must be True in that case.\n",
      "    \n",
      "    A custom opener can be used by passing a callable as *opener*. The\n",
      "    underlying file descriptor for the file object is then obtained by\n",
      "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
      "    file descriptor (passing os.open as *opener* results in functionality\n",
      "    similar to passing None).\n",
      "    \n",
      "    open() returns a file object whose type depends on the mode, and\n",
      "    through which the standard file operations such as reading and writing\n",
      "    are performed. When open() is used to open a file in a text mode ('w',\n",
      "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
      "    a file in a binary mode, the returned class varies: in read binary\n",
      "    mode, it returns a BufferedReader; in write binary and append binary\n",
      "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
      "    a BufferedRandom.\n",
      "    \n",
      "    It is also possible to use a string or bytearray as a file for both\n",
      "    reading and writing. For strings StringIO can be used like a file\n",
      "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
      "    opened in a binary mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(open)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Step_1_1e_Working_with_Files_in_Python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
